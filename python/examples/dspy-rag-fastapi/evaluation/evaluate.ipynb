{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations\n",
    "\n",
    "This notebook shows how to pull traces from a running phoenix instance and evaluate them using the `arize-phoenix-evals` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (1.26.0)\n",
      "Requirement already satisfied: nest_asyncio in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (1.6.0)\n",
      "Requirement already satisfied: arize-phoenix in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (3.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from openai) (2.7.1)\n",
      "Requirement already satisfied: sniffio in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: hdbscan>=0.8.33 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (0.8.33)\n",
      "Requirement already satisfied: jinja2 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (3.1.4)\n",
      "Requirement already satisfied: numpy in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (1.26.4)\n",
      "Requirement already satisfied: openinference-instrumentation in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (0.1.3)\n",
      "Requirement already satisfied: openinference-instrumentation-langchain>=0.1.12 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (0.1.14)\n",
      "Requirement already satisfied: openinference-instrumentation-llama-index>=1.2.0 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (1.3.0)\n",
      "Requirement already satisfied: openinference-instrumentation-openai>=0.1.4 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (0.1.4)\n",
      "Requirement already satisfied: openinference-semantic-conventions>=0.1.5 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (0.1.6)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (1.0.0)\n",
      "Requirement already satisfied: opentelemetry-proto in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (1.0.0)\n",
      "Requirement already satisfied: opentelemetry-sdk in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (1.0.0)\n",
      "Requirement already satisfied: pandas in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (2.2.2)\n",
      "Requirement already satisfied: protobuf<6.0,>=3.20 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (4.25.3)\n",
      "Requirement already satisfied: psutil in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (5.9.8)\n",
      "Requirement already satisfied: pyarrow in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (16.0.0)\n",
      "Requirement already satisfied: requests in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (1.4.2)\n",
      "Requirement already satisfied: scipy in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (1.13.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (2.4.0)\n",
      "Requirement already satisfied: starlette in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (0.37.2)\n",
      "Requirement already satisfied: strawberry-graphql==0.208.2 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (0.208.2)\n",
      "Requirement already satisfied: umap-learn in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (0.5.6)\n",
      "Requirement already satisfied: uvicorn in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (0.29.0)\n",
      "Requirement already satisfied: wrapt in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from arize-phoenix) (1.16.0)\n",
      "Requirement already satisfied: graphql-core<3.3.0,>=3.2.0 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from strawberry-graphql==0.208.2->arize-phoenix) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from strawberry-graphql==0.208.2->arize-phoenix) (2.9.0.post0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: cython<3,>=0.27 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from hdbscan>=0.8.33->arize-phoenix) (0.29.37)\n",
      "Requirement already satisfied: joblib>=1.0 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from hdbscan>=0.8.33->arize-phoenix) (1.4.2)\n",
      "Requirement already satisfied: certifi in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: opentelemetry-api in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from openinference-instrumentation-langchain>=0.1.12->arize-phoenix) (1.0.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from openinference-instrumentation-langchain>=0.1.12->arize-phoenix) (0.19b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from openinference-instrumentation-langchain>=0.1.12->arize-phoenix) (0.43b0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from scikit-learn->arize-phoenix) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from jinja2->arize-phoenix) (2.1.5)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.0.0 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from opentelemetry-exporter-otlp->arize-phoenix) (1.0.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.0.0->opentelemetry-exporter-otlp->arize-phoenix) (1.63.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52.0 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.0.0->opentelemetry-exporter-otlp->arize-phoenix) (1.52.0)\n",
      "Requirement already satisfied: backoff~=1.10.0 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.0.0->opentelemetry-exporter-otlp->arize-phoenix) (1.10.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from pandas->arize-phoenix) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from pandas->arize-phoenix) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from requests->arize-phoenix) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from requests->arize-phoenix) (2.2.1)\n",
      "Requirement already satisfied: numba>=0.51.2 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from umap-learn->arize-phoenix) (0.59.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from umap-learn->arize-phoenix) (0.5.12)\n",
      "Requirement already satisfied: click>=7.0 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from uvicorn->arize-phoenix) (8.1.7)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /Users/juliagomes/Library/Python/3.9/lib/python/site-packages (from numba>=0.51.2->umap-learn->arize-phoenix) (0.42.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.7.0->strawberry-graphql==0.208.2->arize-phoenix) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"arize-phoenix[evals]\" openai nest_asyncio arize-phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run async evaluation in the notebook\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "OPEN_AI_API_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (__init__.py, line 56)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:3550\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 1\u001b[0;36m\n\u001b[0;31m    import phoenix as px\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/phoenix/__init__.py:56\u001b[0;36m\u001b[0m\n\u001b[0;31m    except PhoenixError, e:\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "\n",
    "client = px.Client(endpoint=\"http://localhost:6006\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from phoenix.trace.dsl.helpers import get_qa_with_reference, get_retrieved_documents\n",
    "\n",
    "qa_df = get_qa_with_reference(client)\n",
    "documents_df = get_retrieved_documents(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 800)\n",
    "qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate Retrieval\n",
    "\n",
    "from phoenix.evals import (\n",
    "    OpenAIModel,\n",
    "    RelevanceEvaluator,\n",
    "    run_evals,\n",
    ")\n",
    "\n",
    "relevance_evaluator = RelevanceEvaluator(OpenAIModel(model=\"gpt-4-turbo-preview\", api_key=OPEN_AI_API_KEY))\n",
    "\n",
    "relevance_evals = run_evals(\n",
    "    evaluators=[relevance_evaluator],\n",
    "    dataframe=documents_df,\n",
    "    provide_explanation=True,\n",
    "    concurrency=20,\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_evals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate Responses\n",
    "\n",
    "from phoenix.evals import (\n",
    "    OpenAIModel,\n",
    "    QAEvaluator,\n",
    "    HallucinationEvaluator,\n",
    "    run_evals,\n",
    ")\n",
    "\n",
    "qa_evaluator = QAEvaluator(OpenAIModel(model=\"gpt-4-turbo-preview\", api_key=OPEN_AI_API_KEY))\n",
    "hallucination_evaluator = HallucinationEvaluator(OpenAIModel(model=\"gpt-4-turbo-preview\", api_key=OPEN_AI_API_KEY))\n",
    "\n",
    "qa_evals, hallucination_evals = run_evals(\n",
    "    evaluators=[qa_evaluator, hallucination_evaluator],\n",
    "    dataframe=qa_df,\n",
    "    provide_explanation=True,\n",
    "    concurrency=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add custom eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANSWER_RELEVANCE_TEMPLATE = ''' In this task, you will be presented with a query, a reference text and an answer. The answer is\n",
    "generated to the question based on the reference text. The answer may contain irrelevant information. For the provided list of statements, \n",
    "determine whether each statement is relevant to address the input. If one or more statements are not relevant to the query, please label the answer \n",
    "as \"irrelevant\". If all statements are relevant to the query, please label the answer as \"relevant\".\n",
    "\n",
    "Here is an example where the answer is \"relevant\" because the answer includes a recommendation for a winery with white wines (Chardonnay):\n",
    "    # Query: What's a good place to go wine tasting for white wines in Napa?\n",
    "    # Answer: Castle Winery has amazing Chardonnay.\n",
    "\n",
    "Here is an example where the answer is \"irrelevant\" because the query is asking about white wines, but the answer recommends a winery based on its red wine (Cabernet):\n",
    "    # Query: Where can I go wine tasting for white wines in Napa?\n",
    "    # Answer: Stags Leap has great Cabernet.\n",
    "\n",
    "Please provide your evaluation for the query and answer below:\n",
    "    # Query: {input}\n",
    "    # Answer: {output}\n",
    "\n",
    "Is the answer above relevant or irrelevant to the above query?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import phoenix.experimental.evals.templates.default_templates as templates\n",
    "from phoenix.evals import (\n",
    "    llm_classify,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_qa_relevance_classifications = llm_classify(\n",
    "    dataframe=qa_df, \n",
    "    template=ANSWER_RELEVANCE_TEMPLATE, \n",
    "    model=OpenAIModel(model=\"gpt-4-turbo-preview\", api_key=OPEN_AI_API_KEY), \n",
    "    rails=[\"relevant\", \"irrelevant\"],\n",
    "    provide_explanation=True, #optional to generate explanations for the value produced by the eval LLM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_qa_relevance_classifications.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.trace import DocumentEvaluations, SpanEvaluations\n",
    "\n",
    "# Log the evaluations back to\n",
    "client.log_evaluations(DocumentEvaluations(dataframe=relevance_evals, eval_name=\"document_relevance\"),\n",
    "                       SpanEvaluations(dataframe=custom_qa_relevance_classifications, eval_name=\"answer_relevance\"),\n",
    "                       SpanEvaluations(dataframe=qa_evals, eval_name=\"qa\"),\n",
    "                       SpanEvaluations(dataframe=hallucination_evals, eval_name=\"hallucination\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans_df = px.Client().get_spans_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arize.pandas.logger import Client\n",
    "\n",
    "SPACE_KEY = \"3b83d7a\"\n",
    "API_KEY = \"3e323f22a13bf91e0b5\"\n",
    "\n",
    "\n",
    "if SPACE_KEY == \"SPACE_KEY\" or API_KEY == \"API_KEY\":\n",
    "    raise ValueError(\"❌ NEED TO CHANGE SPACE AND/OR API_KEY\")\n",
    "else:\n",
    "    print(\"✅ Import and Setup Arize Client Done! Now we can start using Arize!\")\n",
    "    \n",
    "arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\n",
    "model_id = \"generative-spans-tutorial-test\" # the model name in Arize\n",
    "model_version = \"1.0\" # (optional) the model version\n",
    "\n",
    "response = arize_client.log_spans(\n",
    "    dataframe=spans_df,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version, # optional\n",
    ")\n",
    "\n",
    "# If successful, the server will return a status_code of 200\n",
    "if response.status_code != 200:\n",
    "    print(f\"❌ logging failed with response code {response.status_code}, {response.text}\")\n",
    "else:\n",
    "    print(f\"✅ You have successfully logged training set to Arize\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
